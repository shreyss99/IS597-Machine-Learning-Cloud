{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SoFLIx-rF-N"
   },
   "source": [
    "# IS597MLC: Model Training Assignment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name:   Shrey Shah\n",
    "### Net ID:  sshah023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This assignment consists of four exercises. You are required to write your code in a cell with a comment \"Insert your code here\" included. You may add more cells if needed. \n",
    "\n",
    "* Please do not change exercise numbers or instruction comments. Also, do not remove or modify if any cells include image of expected outputs.  \n",
    "\n",
    "* Please be aware that there is no one absolute solution to answer a question, i.e., tasks can have multiple correct solution methods you can choose from. \n",
    "\n",
    "* Once you have completed all exercises, update the file name by adding your surname and given name at the end of file name (e.g., IS597MLC_Model_Training_Assignment_Kim_Jenna.ipynb).  \n",
    "\n",
    "* Make sure that all the codes in your updated Jupyter Notebook run properly before you submit it. If a grader encounters an error while attempting to run your codes, points will be deducted even if the code looks correct. If you are sure your files are ready to go, include them into a folder with the same naming convention. Zip the folder into one file and upload it to the UIUC Canvas assignment section.     \n",
    "\n",
    "### Your submitted zipped file should include the following items:  \n",
    "**- Updated Jupyter Notebook with your codes included**  \n",
    "**- dataset file provided by the instructor**   \n",
    "**- output files**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set \n",
    "\n",
    "The goal of this assignment is to build machine learning models to predict whether or not a given article is a randomized controlled trial. Two different machine learning algorithms (Support Vector Machine and Random Forest) will be applied to build prediction models using a data set collected from MEDLINE Corpus. Then, these models will be tested using held-out data and the results will be evaluated.  \n",
    "  \n",
    "The dataset was created by querying the MEDLINE database and downloading the publication record in XML format from PubMed. PubMed (https://pubmed.ncbi.nlm.nih.gov/) is a free online database that supports the search and retrieval of biomedical and life science literature. It contains more than 33 million citations and abstracts of biomedical literature. Since its launch in 1996, PubMed has been maintained by the National Center for Biotechnology Information (NCBI) at the U.S. National Library of Medicine (NLM), which is located at the National Institutes of Health (NIH). MEDLINE is one of the NLM literature archives in which searching is facilitated by PubMed.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect data for this study, Entrez, a PubMed API provided by NCBI, was used to automatically access the database with a code script. It provides 9 E-utilities (https://dataguide.nlm.nih.gov/eutilities/utilities.html#efetch) that can be used for searching a query in the database. The biopython (https://biopython.org/), a python library specially developed for biological computation, was used to communicate with the NCBI Entrez API for retrieving the query results. Queries were restricted to collect the articles written in English and published in the year of 2019. Records were downloaded in XML files, which were then parsed in python to extract the information needed for processing. The final dataset (\"pubmed_rct.txt\") is a txt file with 50,006 instances and 5 attributes: pmid, rct, year, title, abstract. The column named 'rct' contains the target class which includes either 1 (RCT) or 0 (Non-RCT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (Regular) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1-1. Problem Formulation   \n",
    "\n",
    "#### Formulate your research or business question(s) you can think of when you plan to use the dataset provided. You can provide 1 or multiple questions depending on your ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert your answer here:   \n",
    "\n",
    "1) Which are the top 10 topics of interest in the biomedical and life science literature?\n",
    "2) What is the % of similiarity between 2 different articles on the same topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1-2. Create a 'modules.py' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This file should include functions to load and pre-process data. You may reuse the functions you created for previous assignments.\n",
    "* The functions in this file should display proper output to keep track of each step.\n",
    "* The functions are required to include a comment (using # or \"\"\") at the top to briefly describes what your code does.  \n",
    "* Import modules to check if all the functions work properly.   \n",
    "* You may call one or more funtions to prove that they run without an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iCQmTfQRrF-S"
   },
   "outputs": [],
   "source": [
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "#############  Input file name  #############\n",
    "\n",
    "input_filename = \"pubmed_rct.txt\"\n",
    "pubmed_data = pd.read_csv(input_filename, sep=\"\\t\")\n",
    "    \n",
    "#############  Which column to choose?  #############\n",
    "\n",
    "\"\"\"\n",
    "Column options:\n",
    "title text \n",
    "abstract text \n",
    "title + abstract text\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Using the abstract column for the processing\n",
    "column_name = \"title\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "#### Create a function named \"load_data()\" \n",
    "#### that includes all the code you write for Exercise 1.\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "def load_data(filename, colname):\n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "\n",
    "    filename: csv file\n",
    "    colname: column name for texts\n",
    "    return: X and y dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    ## 1. Read in data from input file\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", encoding='utf-8')\n",
    "    \n",
    "    print(\"************** Loading Data ************\", \"\\n\")\n",
    "\n",
    "    # Check number of rows and columns\n",
    "    print(\"No of Rows: {}\".format(df.shape[0]))\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]))\n",
    "\n",
    "    ## 2. Select data needed for processing\n",
    "    print(f\"Selecting columns needed for processing: pmid, {column_name}, rct\", \"\\n\")\n",
    "    df = df[['pmid', column_name, 'rct']]\n",
    "    \n",
    "\n",
    "    ## 3. Cleaning data\n",
    "    # Trim unnecessary spaces for strings\n",
    "    df[colname] = df[colname].apply(lambda x: str(x))\n",
    "\n",
    "    # 3-1. Remove null values\n",
    "    df=df.dropna()\n",
    "\n",
    "    # Check number of rows and columns\n",
    "    print(\"No of rows (After dropping null): {}\".format(df.shape[0]))\n",
    "    print(\"No of columns: {}\".format(df.shape[1]))\n",
    "\n",
    "    # 3-2. Remove duplicates and keep first occurrence\n",
    "    df.drop_duplicates(subset=['pmid'], keep='first', inplace=True)\n",
    "\n",
    "    # Check number of rows and columns\n",
    "    print(\"No of rows (After removing duplicates): {}\".format(df.shape[0]))\n",
    "\n",
    "    # Check the first few instances\n",
    "    print(\"\\n<Data View: First Few Instances>\\n\")\n",
    "    print(df.head(5))\n",
    "    \n",
    "    # 3-3. Check label class\n",
    "    print('\\nClass Counts(label, row): Total')\n",
    "    print(df[\"rct\"].value_counts())\n",
    "    \n",
    "\n",
    "    ## 4. Split into X and y (target)\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_data, y_data):\n",
    "\n",
    "    print(\"\\n************** Spliting Data **************\\n\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test,y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "\n",
    "    ## Check the data view of each data set\n",
    "\n",
    "    ## Data Shape\n",
    "    print(\"Train Data: {}\".format(X_train.shape))\n",
    "    print(\"Val Data: {}\".format(X_val.shape))\n",
    "    print(\"Test Data: {}\".format(X_test.shape))\n",
    "\n",
    "    ## Label Distribution\n",
    "    print('\\nClass Counts(label, row): Train')\n",
    "    print(y_train.value_counts())\n",
    "    print('\\nClass Counts(label, row): Validation')\n",
    "    print(y_val.value_counts())\n",
    "    print('\\nClass Counts(label, row): Test')\n",
    "    print(y_test.value_counts())\n",
    "\n",
    "    ## Display the first 3 instances of X data\n",
    "    print(\"\\nData View: X Train\")\n",
    "    print(X_train.head(3))\n",
    "    print(\"\\nData View: X Val\")\n",
    "    print(X_val.head(3))\n",
    "    print(\"\\nData View: X Test\")\n",
    "    print(X_test.head(3))\n",
    "\n",
    "    ## Reset index\n",
    "\n",
    "    print(\"\\n************** Resetting Index **************\\n\")\n",
    "\n",
    "    # Train Data\n",
    "    X_train=X_train.reset_index(drop=True)\n",
    "    y_train=y_train.reset_index(drop=True)\n",
    "\n",
    "    # Validation Data\n",
    "    X_val=X_val.reset_index(drop=True)\n",
    "    y_val=y_val.reset_index(drop=True)\n",
    "\n",
    "    # Test Data\n",
    "    X_test=X_test.reset_index(drop=True)\n",
    "    y_test=y_test.reset_index(drop=True)\n",
    "\n",
    "    ## Check data\n",
    "\n",
    "    ## Data Shape\n",
    "    print(\"Train Data: {}\".format(X_train.shape))\n",
    "    print(\"Validation Data: {}\".format(X_val.shape))\n",
    "    print(\"Test Data: {}\".format(X_test.shape))\n",
    "\n",
    "    ## Label Distribution\n",
    "    print('\\nClass Counts(label, row): Train\\n')\n",
    "    print(y_train.value_counts())\n",
    "    print('\\nClass Counts(label, row): Val\\n')\n",
    "    print(y_val.value_counts())\n",
    "    print('\\nClass Counts(label, row): Test\\n')\n",
    "    print(y_test.value_counts())\n",
    "\n",
    "    ## Display the first 3 instances of X data\n",
    "    print(\"\\nData View: X Train\")\n",
    "    print(X_train.head(3))\n",
    "    print(\"\\nData View: X Val\")\n",
    "    print(X_val.head(3))\n",
    "    print(\"\\nData View: X Test\")\n",
    "    print(X_test.head(3))\n",
    "    \n",
    "    return (X_train, X_val, X_test, y_train, y_val, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_data_raw):\n",
    "    \"\"\"\n",
    "       Preprocess data with lowercase conversion, punctuation removal, tokenization, stemming\n",
    "\n",
    "       X_data_raw: X data in dataframe\n",
    "       return: transformed dataframe\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n************** Pre-processed Data **************\\n\")\n",
    "    \n",
    "    X_data=X_data_raw.iloc[:, -1].astype(str)\n",
    "    print(f\"\\nTrain Data: {X_data.shape}\")\n",
    "    \n",
    "    ## 1. convert all characters to lowercase\n",
    "    X_data = X_data.map(lambda x: x.lower())\n",
    "\n",
    "    ## 2. remove punctuation\n",
    "    X_data = X_data.str.replace('[^\\w\\s]', '')\n",
    "\n",
    "    ## 3. tokenize sentence\n",
    "    X_data = X_data.apply(nltk.word_tokenize)\n",
    "\n",
    "    ## 4. remove stopwords\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "    X_data = X_data.apply(lambda x: [word for word in x if word not in stopword_list])\n",
    "\n",
    "    ## 5. stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    X_data = X_data.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "\n",
    "    ## 6. removing unnecessary space\n",
    "    X_data = X_data.apply(lambda x: \" \".join(x))\n",
    "\n",
    "    # Check data view\n",
    "    print(\"\\nData View: X Train\\n\")\n",
    "    print(X_data.head(3))\n",
    "\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data ************ \n",
      "\n",
      "No of Rows: 50006\n",
      "No of Columns: 5\n",
      "Selecting columns needed for processing: pmid, title, rct \n",
      "\n",
      "No of rows (After dropping null): 50006\n",
      "No of columns: 3\n",
      "No of rows (After removing duplicates): 50006\n",
      "\n",
      "<Data View: First Few Instances>\n",
      "\n",
      "       pmid                                              title  rct\n",
      "0  24900659  Probing the binding site of abl tyrosine kinas...    0\n",
      "1  29492752  Variability in Bariatric Surgical Care Among V...    0\n",
      "2  30574804  Maternal antibiotic prophylaxis affects Bifido...    0\n",
      "3  29679827  Environmental impact assessment of alfalfa (Me...    0\n",
      "4  30117518  Sandwiched spherical tin dioxide/graphene with...    0\n",
      "\n",
      "Class Counts(label, row): Total\n",
      "rct\n",
      "0    40007\n",
      "1     9999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_data, y_data = load_data(input_filename, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Spliting Data **************\n",
      "\n",
      "Train Data: (40004, 2)\n",
      "Val Data: (5001, 2)\n",
      "Test Data: (5001, 2)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "rct\n",
      "0    32005\n",
      "1     7999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Validation\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data View: X Train\n",
      "           pmid                                              title\n",
      "23663  30472200  Prenatal propofol exposure downregulates NMDA ...\n",
      "40088  27385766  Protein N-terminal acetylation is required for...\n",
      "44930  24423084  Let's face it: facial emotion processing is im...\n",
      "\n",
      "Data View: X Val\n",
      "           pmid                                              title\n",
      "36841  31503331  Acute hemolytic transfusion reaction associate...\n",
      "21713  22902894  The role of ovarian hormones in sexual reward ...\n",
      "6131   29944726  In vitro cytotoxicity of superheated steam hyd...\n",
      "\n",
      "Data View: X Test\n",
      "           pmid                                              title\n",
      "36176  29095290  The pancreatic juice length in the stent tube ...\n",
      "668    26146239  Psychometric properties of the Patient Activat...\n",
      "18895  26206985  [Copeptin - stable C-terminal fragment of pre-...\n",
      "\n",
      "************** Resetting Index **************\n",
      "\n",
      "Train Data: (40004, 2)\n",
      "Validation Data: (5001, 2)\n",
      "Test Data: (5001, 2)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "\n",
      "rct\n",
      "0    32005\n",
      "1     7999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Val\n",
      "\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data View: X Train\n",
      "       pmid                                              title\n",
      "0  30472200  Prenatal propofol exposure downregulates NMDA ...\n",
      "1  27385766  Protein N-terminal acetylation is required for...\n",
      "2  24423084  Let's face it: facial emotion processing is im...\n",
      "\n",
      "Data View: X Val\n",
      "       pmid                                              title\n",
      "0  31503331  Acute hemolytic transfusion reaction associate...\n",
      "1  22902894  The role of ovarian hormones in sexual reward ...\n",
      "2  29944726  In vitro cytotoxicity of superheated steam hyd...\n",
      "\n",
      "Data View: X Test\n",
      "       pmid                                              title\n",
      "0  29095290  The pancreatic juice length in the stent tube ...\n",
      "1  26146239  Psychometric properties of the Patient Activat...\n",
      "2  26206985  [Copeptin - stable C-terminal fragment of pre-...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Pre-processed Data **************\n",
      "\n",
      "\n",
      "Train Data: (40004,)\n",
      "\n",
      "Data View: X Train\n",
      "\n",
      "0    prenat propofol exposur downregul nmda recepto...\n",
      "1    protein n-termin acetyl requir embryogenesi ar...\n",
      "2    let 's face : facial emot process impair bipol...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "preprocessed_X_train = preprocess_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (Regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2-1. Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function named \"fit_model\" that conducts model fitting on input data.  \n",
    "* This function should include three parameters: X, y, modelname.\n",
    "* This function should contain the options to choose any of the following ML algorithms:  \n",
    "  - Decision Tree\n",
    "  - Logistic Regression  \n",
    "  - Support Vector Machines  \n",
    "  - Random Forest    \n",
    "* Note that the function is required to include a comment at the top to briefly describes what your code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def fit_model(X, y, modelname):\n",
    "    \"\"\"\n",
    "    Fits a machine learning model to input data.\n",
    "\n",
    "    Parameters:\n",
    "    X: Input features.\n",
    "    y: Target variable.\n",
    "    modelname: Name of the machine learning algorithm to use.\n",
    "               Choose from: Decision Tree, Logistic Regression, Support Vector Machines, Random Forest.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mapping modelname to corresponding machine learning algorithm\n",
    "    models = {\n",
    "        'Decision_tree': DecisionTreeClassifier(),\n",
    "        'Logistic_regression': LogisticRegression(),\n",
    "        'Support_vector_machine': SVC(),\n",
    "        'Random_forest': RandomForestClassifier()\n",
    "    }\n",
    "    \n",
    "    # Checking if the specified modelname is valid\n",
    "    if modelname not in models:\n",
    "        raise ValueError(\"Invalid modelname. Choose from: Decision_tree, Logistic_regression, Support_vector_machine, Random_forest.\")\n",
    "    \n",
    "    # Fitting the selected model to the data\n",
    "    \n",
    "    print(f\"\\n************** Training Model: {modelname} **************\\n\")\n",
    "    \n",
    "    model = models[modelname]\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2-2. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function named 'evaluate_model' that produces confusion matrix.  \n",
    "* This function should require two parameters that take predicted labels and actual labels.  \n",
    "* Note that the function is required to include a comment at the top to briefly describes what your code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def evaluate_model(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix for evaluating model performance.\n",
    "\n",
    "    Parameters:\n",
    "    y_pred Predicted labels.\n",
    "    y_true: Actual labels.\n",
    "\n",
    "    Returns:\n",
    "    array: Confusion matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n************** Model Evaluation **************\\n\")\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    \n",
    "    # Computing the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (Regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3-1. Create a Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a function named \"main_function\" that automatically conducts the entire process from loading and transforming data to model performance evaluation. \n",
    "* For data splitting, set the random_state parameter to a specific numeber (e.g., random_state=42) so that the grader can replicate the same data when running your code.  \n",
    "* Before fitting a ML model, you are required to transform textual data into numerical representations.   \n",
    "* You may use one of the vectorization schema shown in class, such as TF-IDF, Bag-of-Words, etc. or try out other strategies if you want to.   \n",
    "* When running this function, output corresponding to each step should be displayed to keep track of the process.  \n",
    "* You may refer a sample output file (\"output_title_LR.txt\") provided for Exercise 4.  \n",
    "* Note that the function is required to include a comment at the top to briefly describes what your code does. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def main_function(filename, colname):\n",
    "    \"\"\"\n",
    "    Automates the process from loading and transforming data to model performance evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): Name of the CSV file containing data.\n",
    "    colname (str): Column name for textual data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    X, y = load_data(filename, colname)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
    "\n",
    "    # Preprocess textual data\n",
    "    X_train_processed = preprocess_data(X_train)\n",
    "    X_val_processed = preprocess_data(X_val)\n",
    "    X_test_processed = preprocess_data(X_test)\n",
    "\n",
    "    # Transform textual data into numerical representations using the TF-IDF vectorizer\n",
    "    # Fit the vectorizer on the X_train, X_val, and X_test dataset\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train_processed)\n",
    "    X_val_vectorized = vectorizer.transform(X_val_processed)\n",
    "    X_test_vectorized = vectorizer.transform(X_test_processed)\n",
    "\n",
    "    # Fit model (example using Logistic regression)\n",
    "    model = fit_model(X_train_vectorized, y_train, 'Logistic_regression')\n",
    "    print(\"\\nModel fitted successfully!\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    print(\"\\n************** Getting predictions **************\\n\")\n",
    "    y_pred_test = model.predict(X_test_vectorized)\n",
    "\n",
    "    # Evaluateing model performance\n",
    "    print(\"\\n************** Evaluating performance **************\\n\")\n",
    "    print(evaluate_model(y_pred_test, y_test))\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3-2. Run the Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Call the main function with the following requirements:  \n",
    "  - Column name: title  \n",
    "  - Model type: Logistic Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#############  1. Set Parameter Values  ##############\n",
    "######################################################\n",
    "\n",
    "    \n",
    "#############  1-1. Input file name  #############\n",
    "\n",
    "input_filename = \"pubmed_rct.txt\"\n",
    "    \n",
    "    \n",
    "#############  1-2. Which column to choose?  #############\n",
    "\n",
    "\"\"\"\n",
    "Column options:\n",
    "title text \n",
    "abstract text \n",
    "title + abstract text   \n",
    "\"\"\"\n",
    "     \n",
    "column_name = \"title\"         \n",
    "\n",
    "\n",
    "#############  1-3. Which ML model to use?  #############\n",
    "    \n",
    "\"\"\"\n",
    "Model options:\n",
    "    \n",
    "Decision_tree\n",
    "Logisitic_regression\n",
    "Support_vector_machine\n",
    "Random_forest\n",
    "\"\"\"\n",
    "    \n",
    "model_type = \"Logisitic_regression\"                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** Loading Data ************ \n",
      "\n",
      "No of Rows: 50006\n",
      "No of Columns: 5\n",
      "Selecting columns needed for processing: pmid, title, rct \n",
      "\n",
      "No of rows (After dropping null): 50006\n",
      "No of columns: 3\n",
      "No of rows (After removing duplicates): 50006\n",
      "\n",
      "<Data View: First Few Instances>\n",
      "\n",
      "       pmid                                              title  rct\n",
      "0  24900659  Probing the binding site of abl tyrosine kinas...    0\n",
      "1  29492752  Variability in Bariatric Surgical Care Among V...    0\n",
      "2  30574804  Maternal antibiotic prophylaxis affects Bifido...    0\n",
      "3  29679827  Environmental impact assessment of alfalfa (Me...    0\n",
      "4  30117518  Sandwiched spherical tin dioxide/graphene with...    0\n",
      "\n",
      "Class Counts(label, row): Total\n",
      "rct\n",
      "0    40007\n",
      "1     9999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "************** Spliting Data **************\n",
      "\n",
      "Train Data: (40004, 2)\n",
      "Val Data: (5001, 2)\n",
      "Test Data: (5001, 2)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "rct\n",
      "0    32005\n",
      "1     7999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Validation\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data View: X Train\n",
      "           pmid                                              title\n",
      "23663  30472200  Prenatal propofol exposure downregulates NMDA ...\n",
      "40088  27385766  Protein N-terminal acetylation is required for...\n",
      "44930  24423084  Let's face it: facial emotion processing is im...\n",
      "\n",
      "Data View: X Val\n",
      "           pmid                                              title\n",
      "36841  31503331  Acute hemolytic transfusion reaction associate...\n",
      "21713  22902894  The role of ovarian hormones in sexual reward ...\n",
      "6131   29944726  In vitro cytotoxicity of superheated steam hyd...\n",
      "\n",
      "Data View: X Test\n",
      "           pmid                                              title\n",
      "36176  29095290  The pancreatic juice length in the stent tube ...\n",
      "668    26146239  Psychometric properties of the Patient Activat...\n",
      "18895  26206985  [Copeptin - stable C-terminal fragment of pre-...\n",
      "\n",
      "************** Resetting Index **************\n",
      "\n",
      "Train Data: (40004, 2)\n",
      "Validation Data: (5001, 2)\n",
      "Test Data: (5001, 2)\n",
      "\n",
      "Class Counts(label, row): Train\n",
      "\n",
      "rct\n",
      "0    32005\n",
      "1     7999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Val\n",
      "\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Counts(label, row): Test\n",
      "\n",
      "rct\n",
      "0    4001\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data View: X Train\n",
      "       pmid                                              title\n",
      "0  30472200  Prenatal propofol exposure downregulates NMDA ...\n",
      "1  27385766  Protein N-terminal acetylation is required for...\n",
      "2  24423084  Let's face it: facial emotion processing is im...\n",
      "\n",
      "Data View: X Val\n",
      "       pmid                                              title\n",
      "0  31503331  Acute hemolytic transfusion reaction associate...\n",
      "1  22902894  The role of ovarian hormones in sexual reward ...\n",
      "2  29944726  In vitro cytotoxicity of superheated steam hyd...\n",
      "\n",
      "Data View: X Test\n",
      "       pmid                                              title\n",
      "0  29095290  The pancreatic juice length in the stent tube ...\n",
      "1  26146239  Psychometric properties of the Patient Activat...\n",
      "2  26206985  [Copeptin - stable C-terminal fragment of pre-...\n",
      "\n",
      "************** Pre-processed Data **************\n",
      "\n",
      "\n",
      "Train Data: (40004,)\n",
      "\n",
      "Data View: X Train\n",
      "\n",
      "0    prenat propofol exposur downregul nmda recepto...\n",
      "1    protein n-termin acetyl requir embryogenesi ar...\n",
      "2    let 's face : facial emot process impair bipol...\n",
      "Name: title, dtype: object\n",
      "\n",
      "************** Pre-processed Data **************\n",
      "\n",
      "\n",
      "Train Data: (5001,)\n",
      "\n",
      "Data View: X Train\n",
      "\n",
      "0    acut hemolyt transfus reaction associ anti-mta...\n",
      "1    role ovarian hormon sexual reward state femal ...\n",
      "2    vitro cytotox superh steam hydrolyz oligo ( ( ...\n",
      "Name: title, dtype: object\n",
      "\n",
      "************** Pre-processed Data **************\n",
      "\n",
      "\n",
      "Train Data: (5001,)\n",
      "\n",
      "Data View: X Train\n",
      "\n",
      "0    pancreat juic length stent tube predict factor...\n",
      "1    psychometr properti patient activ measure-13 a...\n",
      "2    [ copeptin - stabl c-termin fragment pre-prova...\n",
      "Name: title, dtype: object\n",
      "\n",
      "************** Training Model: Logistic_regression **************\n",
      "\n",
      "\n",
      "Model fitted successfully!\n",
      "\n",
      "\n",
      "************** Getting predictions **************\n",
      "\n",
      "\n",
      "************** Evaluating performance **************\n",
      "\n",
      "\n",
      "************** Model Evaluation **************\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[3918   83]\n",
      " [ 393  607]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94      4311\n",
      "           1       0.61      0.88      0.72       690\n",
      "\n",
      "    accuracy                           0.90      5001\n",
      "   macro avg       0.79      0.89      0.83      5001\n",
      "weighted avg       0.93      0.90      0.91      5001\n",
      "\n",
      "CPU times: user 18.9 s, sys: 79.3 ms, total: 19 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "         \n",
    "    main_function(input_filename, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3-3. Performance Evaluation Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interpret the results from the confusion matrix generated in Ex3-2. Provide the following 4 evaluation scores for our target class (both RCT and Non-RCT):  \n",
    "  - Accuracy  \n",
    "  - Precision  \n",
    "  - Recall  \n",
    "  - F1  \n",
    "* Demonstrate how these scores for each class are calculated with mathmatical equation.   \n",
    "* Use values in the confusion matrix such as true positive to explain how the evaluation scores are created.\n",
    "* The numbers used in the equation should match the ones in the confusion matrix generated by the main function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide evaluation scores for each class.\n",
    "\n",
    "1. Class 0 (Non-RCT)\n",
    "- Accuracy = 0.905\n",
    "- Precision = 0.979\n",
    "- Recall = 0.909\n",
    "- F1 = 0.942\n",
    "\n",
    "2. Class 1 (RCT)\n",
    "- Accuracy = 0.905\n",
    "- Precision = 0.607\n",
    "- Recall = 0.879\n",
    "- F1 = 0.718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show how each score is calculated with numbers in confusion matrix.\n",
    "\n",
    "1. Class 0 (Non-RCT)  \n",
    "- Accuracy = (TP + TN)/(TP + TN + FP + FN) = (3918 + 607)/(3918 + 607 + 83 + 393) = 4311/5001 = 0.905\n",
    "- Precision = (TP)/(TP + FP) = 3918/(3918 + 83) = 3918/4001 = 0.979\n",
    "- Recall = (TP)/(TP + FN) = 3918/(3918 + 393) = 3918/4311 = 0.909\n",
    "- F1 = 2 * Precision * Recall / (Precision + Recall) = 2 * 0.979 * 0.909/(0.979 + 0.909) = 1.779/1.888 = 0.942\n",
    "\n",
    "2. Class 1 (RCT)\n",
    "- Accuracy = (TP + TN)/(TP + TN + FP + FN) = (3918 + 607)/(3918 + 607 + 83 + 393) = 4311/5001 = 0.905\n",
    "- Precision = (TP)/(TP + FP) = 607/(607 + 393) = 607/1000 = 0.607\n",
    "- Recall = (TP)/(TP + FN) = 607/(607 + 83) = 607/690 = 0.879\n",
    "- F1 = 2 * Precision * Recall / (Precision + Recall) = 2 * 0.607 * 0.879/(0.607 + 0.879) = 1.067/1.486 = 0.718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtuA57AQwTjA"
   },
   "source": [
    "# Exercise 4 (Challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a file named \"modules_updated.py\" that includes all the functions you created for previous exercises.  \n",
    "* Revise the main_function() so that it also writes the output of each step into a separate file named like output_column_model.txt.  \n",
    "* The output in the file should look somthing like the one in the sample file provided (\"output_title_LR.txt\").   \n",
    "* After running the code, the same output is expected to be shown in both the Jupyter Notebook and an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules_updated import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(filename, colname):\n",
    "    \"\"\"\n",
    "    Automates the process from loading and transforming data to model performance evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): Name of the CSV file containing data.\n",
    "    colname (str): Column name for textual data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Define model name\n",
    "    model_type = \"Logistic_regression\"\n",
    "\n",
    "    # Define log file name\n",
    "    log_file = f\"output_{colname}_{model_type}.txt\"\n",
    "\n",
    "    # Open log file for writing\n",
    "    with open(log_file, 'w') as f:\n",
    "        # Load data\n",
    "        X, y = load_data_new(filename, colname, f)\n",
    "        print(\"\\n\", file=f)\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = split_data_new(X, y, f)\n",
    "        print(\"\\n\", file=f)\n",
    "\n",
    "        # Preprocess textual data\n",
    "        X_train_processed = preprocess_data_new(X_train, f)\n",
    "        X_val_processed = preprocess_data_new(X_val, f)\n",
    "        X_test_processed = preprocess_data_new(X_test, f)\n",
    "\n",
    "        # Transform textual data into numerical representations using the TF-IDF vectorizer\n",
    "        # Fit the vectorizer on the X_train, X_val, and X_test dataset\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_train_vectorized = vectorizer.fit_transform(X_train_processed)\n",
    "        X_val_vectorized = vectorizer.transform(X_val_processed)\n",
    "        X_test_vectorized = vectorizer.transform(X_test_processed)\n",
    "\n",
    "        # Fit model (example using Logistic regression)\n",
    "        model = fit_model_new(X_train_vectorized, y_train, model_type, f)\n",
    "        print(\"\\nModel fitted successfully!\\n\", file=f)\n",
    "        \n",
    "        # Predictions\n",
    "        print(\"\\n************** Getting predictions **************\\n\", file=f)\n",
    "        y_pred_test = model.predict(X_test_vectorized)\n",
    "\n",
    "        # Evaluate model performance\n",
    "        print(\"\\n************** Evaluating performance **************\\n\", file=f)\n",
    "        evaluate_model_new(y_pred_test, y_test, f)\n",
    "        print(\"\\nClassification Report:\\n\", file=f)\n",
    "        print(classification_report(y_pred_test, y_test), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#############  1. Set Parameter Values  ##############\n",
    "######################################################\n",
    "\n",
    "    \n",
    "#############  1-1. Input file name  #############\n",
    "\n",
    "input_filename = \"pubmed_rct.txt\"\n",
    "    \n",
    "    \n",
    "#############  1-2. Which column to choose?  #############\n",
    "\n",
    "\"\"\"\n",
    "Column options:\n",
    "title text \n",
    "abstract text \n",
    "title + abstract text   \n",
    "\"\"\"\n",
    "     \n",
    "column_name = \"title\"         \n",
    "\n",
    "\n",
    "#############  1-3. Which ML model to use?  #############\n",
    "    \n",
    "\"\"\"\n",
    "Model options:\n",
    "    \n",
    "Decision Tree\n",
    "Logisitic regression\n",
    "Support Vector Machines\n",
    "Random Forest\n",
    "\"\"\"\n",
    "    \n",
    "model_type = \"Logisitic_regression\"                                            \n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pYt_qbIcrF-a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Processing Completed **************\n",
      "\n",
      "CPU times: user 19.1 s, sys: 85.6 ms, total: 19.2 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "\n",
    "            \n",
    "    main_function(input_filename, column_name)\n",
    "    \n",
    "        \n",
    "    print(\"\\n************** Processing Completed **************\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
